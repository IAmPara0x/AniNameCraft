{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea34186-4e1e-4474-8dbe-1e3333985d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5eff0d-c558-4c9a-af60-a28c59f6af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./characters_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a636e918-a3e4-40ed-bee9-5d39ea5b5bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Name', 'Alias', 'Gender', 'Hair Color', 'Love Rank', 'Hate Rank',\n",
       "       'Eye color', 'Birthday', 'Blood Type', 'Tags', 'Love Count',\n",
       "       'Hate Count', 'Description', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf00d9f-18b0-4e4f-81a3-8b046e093e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_name(name):\n",
    "    chars = [*name]\n",
    "    len_chars = len(chars)\n",
    "    idx = 0\n",
    "    while idx < len_chars and chars[idx].isalpha():\n",
    "        idx += 1\n",
    "    \n",
    "    return \"\".join(chars[:idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d7a347-0313-4bbf-bcb4-d559f921fef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yui'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(\"Yui\\nyaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1fb267-8cf3-4a54-b5f7-363feeca2894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc82c4f-1ab5-4751-856e-459a06e33b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = list(set([*map(lambda full_name: get_name(full_name).lower(), df[df[\"Gender\"] == \"Female\"][\"Name\"])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a3f294-127f-423b-bc58-55c62ec09165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(lambda n: len(n), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1360cc8d-eb1a-4a53-94fd-7b997c93c626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7034ad-6202-4351-a5ab-818f89e01a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "END_TOKEN = \"<end>\"\n",
    "PAD_TOKEN = \"<pad>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f9107b-deee-4de2-881e-683aa4daf873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens2idx = {token: idx for idx, token in enumerate([chr(i) for i in range(97,123)] + [END_TOKEN, PAD_TOKEN])}\n",
    "idx2tokens = {v:k for k,v in tokens2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bcb5718-4e0c-4c9a-9a65-c98c99dc2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_encode(name, max_len=20):\n",
    "    \n",
    "    name = [*name[:max_len]]\n",
    "    name.append(END_TOKEN)\n",
    "    \n",
    "    mask = [1 for _ in range(len(name))]\n",
    "    \n",
    "    \n",
    "    while len(name) < max_len + 1:\n",
    "        name.append(PAD_TOKEN)\n",
    "        mask.append(0)\n",
    "        \n",
    "    return {\"tokens\": [tokens2idx[c] for c in name], \"mask\": mask}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0fea6b5-446d-4ee2-9f3b-21e41cecf9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('palp',\n",
       " {'tokens': [15,\n",
       "   0,\n",
       "   11,\n",
       "   15,\n",
       "   26,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27,\n",
       "   27],\n",
       "  'mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = random.choice(data)\n",
    "\n",
    "name, tokenizer_encode(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5334ba-e990-4e71-87c2-6b88881578ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size=28, embd_dim=512, hidden_dim=512):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.W_hh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_xh = nn.Linear(embd_dim, hidden_dim)\n",
    "        self.W_hy = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        self.h = nn.Parameter(torch.randn(embd_dim)); self.h.retain_grad()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_dim)\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, x, device=\"cpu\"):\n",
    "\n",
    "        # h = self.h\n",
    "        x = self.embeddings(x)\n",
    "        batch_size, seq_len, embd_dim = x.shape\n",
    "\n",
    "\n",
    "        output = torch.zeros(batch_size, seq_len - 1, self.vocab_size).to(device)\n",
    "        hiddens = torch.zeros(batch_size, self.hidden_dim).to(device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            hiddens[i] = self.h\n",
    "        \n",
    "\n",
    "        for i in range(seq_len - 1):\n",
    "            hiddens = F.tanh(self.W_hh(hiddens) + self.W_xh(x[:,i]))\n",
    "            y = self.W_hy(hiddens)\n",
    "            output[:,i] = y\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a067afa7-3713-4bb3-84ed-16f929ba2e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255dd128-7a0a-40ed-bf4c-0e0c8fbe9703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614729ec-89dc-48d1-bf01-00a1c7d67289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(tokenizer_encode(name)[\"tokens\"]).reshape(1,-1).to(DEVICE)\n",
    "y = model(x, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "652a65c9-b83d-4e9f-b798-d4155bd4ebf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(input_tokens, y_pred):\n",
    "        \n",
    "    y_true = input_tokens[:, 1:].clone()\n",
    "    y_true.masked_fill_(y_true == tokens2idx[PAD_TOKEN], -100)\n",
    "    # print(y_pred.shape, y_true.shape)\n",
    "    loss = F.cross_entropy(y_pred.reshape(-1,28), y_true.reshape(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29a0867d-add5-48ee-8a2b-ca245b6593f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e626170f-40f2-4128-9717-5b3b45f7e95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17314it [00:00, 304608.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096\n",
      "1281\n",
      "2068\n",
      "2150\n",
      "2660\n",
      "3023\n",
      "3347\n",
      "3891\n",
      "3963\n",
      "4079\n",
      "4087\n",
      "4130\n",
      "4527\n",
      "4793\n",
      "5200\n",
      "5222\n",
      "5881\n",
      "5947\n",
      "6022\n",
      "6715\n",
      "6812\n",
      "6952\n",
      "7448\n",
      "7988\n",
      "8270\n",
      "8884\n",
      "9244\n",
      "9629\n",
      "10113\n",
      "10133\n",
      "10767\n",
      "11245\n",
      "12902\n",
      "13915\n",
      "14693\n",
      "15079\n",
      "15936\n",
      "16037\n",
      "16119\n",
      "16178\n",
      "16828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "masks = []\n",
    "\n",
    "for idx, name in tqdm(enumerate(data)):\n",
    "    try:\n",
    "        tmp = tokenizer_encode(name)\n",
    "        xs.append(tmp[\"tokens\"])\n",
    "        masks.append(tmp[\"mask\"])\n",
    "    except Exception as e:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d45b44b-7b80-47bd-8525-f6fa7a1d2cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = torch.tensor(xs).to(DEVICE)\n",
    "masks = torch.tensor(masks).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "818dbb64-6144-4f59-996d-25818cb1a9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "optimizer = AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "304a2f09-ca37-4063-9e4c-443e8d00deca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, input_str):\n",
    "    \n",
    "    while True:\n",
    "        x = torch.tensor(tokenizer_encode(input_str, max_len=len(input_str))[\"tokens\"]).reshape(1,-1).to(DEVICE)\n",
    "        last_logits = model(x, device=DEVICE).squeeze()[-1]\n",
    "        new_char_idx = last_logits.softmax(dim=-1).argmax().item()\n",
    "    \n",
    "        if new_char_idx == tokens2idx[END_TOKEN]:\n",
    "            # print(input_str)\n",
    "            break\n",
    "        \n",
    "        input_str = input_str + idx2tokens[new_char_idx]\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b72990ea-1577-4efa-9796-941b13446491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.9715145826339722 | training loss: 2.004373825365497:  21%|███████████████████████▏                                                                                        | 56/270 [00:01<00:03, 61.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step count: 50 | name: yuki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.9761524200439453 | training loss: 1.9901961886457034:  41%|█████████████████████████████████████████████▋                                                                | 112/270 [00:01<00:02, 61.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step count: 100 | name: yurin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.06046986579895 | training loss: 1.989960026593856:  60%|███████████████████████████████████████████████████████████████████▍                                             | 161/270 [00:02<00:01, 61.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step count: 150 | name: yuuka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.1162972450256348 | training loss: 1.9905264237017002:  78%|█████████████████████████████████████████████████████████████████████████████████████▌                        | 210/270 [00:03<00:00, 63.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step count: 200 | name: yung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.124035596847534 | training loss: 1.9857862685375287:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 259/270 [00:04<00:00, 61.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step count: 250 | name: yuuka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.97346830368042 | training loss: 1.984521743544826: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 270/270 [00:04<00:00, 62.05it/s]\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "step_count = 0\n",
    "inference_per_step = 50\n",
    "\n",
    "for batch_start_idx in (tbar := tqdm(range(0,17273,BATCH_SIZE))):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    input_xs = xs[batch_start_idx: batch_start_idx + BATCH_SIZE]\n",
    "    input_masks = masks[batch_start_idx: batch_start_idx + BATCH_SIZE]\n",
    "    \n",
    "    pred_ys = model(input_xs, device=DEVICE)\n",
    "    loss = criterion(input_xs,pred_ys)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    step_count += 1\n",
    "    training_loss.append(loss.item())\n",
    "    \n",
    "    if step_count % inference_per_step == 0:\n",
    "        model.eval()\n",
    "        name = inference(model, \"yu\")\n",
    "        print(f\"step count: {step_count} | name: {name}\")\n",
    "        model.train()\n",
    "    \n",
    "    \n",
    "    tbar.set_description(f\"loss: {loss.item()} | training loss: {np.mean(training_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40a5092c-7e0c-4528-8fee-d7b94067ef7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (W_hh): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (W_xh): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (W_hy): Linear(in_features=512, out_features=28, bias=True)\n",
       "  (embeddings): Embedding(28, 512)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01c08e49-44ce-41d4-90b7-deb1526db442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ichina'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(model, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8fee2c4-0582-4d73-91c4-c82674fb1fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17314"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857cf7c-7809-4c61-98ff-77315c26f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
