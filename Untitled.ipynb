{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2009cc-3301-498e-bf59-fdda9c4bb0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53c6aad-21a7-4499-a143-dd99b55793e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./characters_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f16ae29-bd36-485a-a0d8-23e3a867e09e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Name', 'Alias', 'Gender', 'Hair Color', 'Love Rank', 'Hate Rank',\n",
       "       'Eye color', 'Birthday', 'Blood Type', 'Tags', 'Love Count',\n",
       "       'Hate Count', 'Description', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9401b424-38d9-44d3-85bf-e3ef221acaaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Alias</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hair Color</th>\n",
       "      <th>Love Rank</th>\n",
       "      <th>Hate Rank</th>\n",
       "      <th>Eye color</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Love Count</th>\n",
       "      <th>Hate Count</th>\n",
       "      <th>Description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>Ryuzaki</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>Black</td>\n",
       "      <td>October 31, 1979</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Analytical, Barefoot, Detectives, Eye Bags, Sw...</td>\n",
       "      <td>44.829</td>\n",
       "      <td>3.447</td>\n",
       "      <td>Secretive, meticulous and cunning, L's desire ...</td>\n",
       "      <td>https://www.anime-planet.com/characters/l-deat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Haru YOSHIDA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>346.000</td>\n",
       "      <td>4.172</td>\n",
       "      <td>Black</td>\n",
       "      <td>April 2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>High School Students, Hot-Headed, Teenagers</td>\n",
       "      <td>4.669</td>\n",
       "      <td>124</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.anime-planet.com/characters/haru-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Shinobu MAEHARA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Female</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2.942</td>\n",
       "      <td>9.110</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Cooks, Crybabies, Middle School Students, Shy</td>\n",
       "      <td>823</td>\n",
       "      <td>53</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.anime-planet.com/characters/shinob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chizuru OSHIMA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>3.877</td>\n",
       "      <td>1.801</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Class Representatives, Glasses, High School St...</td>\n",
       "      <td>633</td>\n",
       "      <td>269</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.anime-planet.com/characters/chizur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yuuzan YOSHIDA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>3.577</td>\n",
       "      <td>2.819</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>684</td>\n",
       "      <td>180</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.anime-planet.com/characters/yuuzan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID             Name    Alias  Gender Hair Color  Love Rank  Hate Rank  \\\n",
       "0   0                L  Ryuzaki    Male      Black      1.000     48.000   \n",
       "1   1     Haru YOSHIDA  Unknown    Male      Black    346.000      4.172   \n",
       "2   2  Shinobu MAEHARA  Unknown  Female       Blue      2.942      9.110   \n",
       "3   3   Chizuru OSHIMA  Unknown  Female      Black      3.877      1.801   \n",
       "4   4   Yuuzan YOSHIDA  Unknown    Male      Black      3.577      2.819   \n",
       "\n",
       "  Eye color          Birthday Blood Type  \\\n",
       "0     Black  October 31, 1979    Unknown   \n",
       "1     Black           April 2    Unknown   \n",
       "2   Unknown           Unknown    Unknown   \n",
       "3   Unknown           Unknown    Unknown   \n",
       "4   Unknown           Unknown    Unknown   \n",
       "\n",
       "                                                Tags Love Count Hate Count  \\\n",
       "0  Analytical, Barefoot, Detectives, Eye Bags, Sw...     44.829      3.447   \n",
       "1        High School Students, Hot-Headed, Teenagers      4.669        124   \n",
       "2      Cooks, Crybabies, Middle School Students, Shy        823         53   \n",
       "3  Class Representatives, Glasses, High School St...        633        269   \n",
       "4                                            Unknown        684        180   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Secretive, meticulous and cunning, L's desire ...   \n",
       "1                                            Unknown   \n",
       "2                                            Unknown   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.anime-planet.com/characters/l-deat...  \n",
       "1  https://www.anime-planet.com/characters/haru-y...  \n",
       "2  https://www.anime-planet.com/characters/shinob...  \n",
       "3  https://www.anime-planet.com/characters/chizur...  \n",
       "4  https://www.anime-planet.com/characters/yuuzan...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aba3f23-4465-4cf6-92b1-7d22d812d74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_first_name(name):\n",
    "    chars = [*name]\n",
    "    len_chars = len(chars)\n",
    "    idx = 0\n",
    "    while idx < len_chars and chars[idx].isalpha() and chars[idx].isascii():\n",
    "        idx += 1\n",
    "    \n",
    "    return \"\".join(chars[:idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ca797b-9211-4b3e-a6ad-25d34d0f21f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "female_names = list(set([*map(lambda full_name: get_first_name(full_name).lower(), df[df[\"Gender\"] == \"Female\"][\"Name\"])]))\n",
    "male_names = list(set([*map(lambda full_name: get_first_name(full_name).lower(), df[df[\"Gender\"] == \"Male\"][\"Name\"])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efca88f7-0789-4671-a83f-8a9ee9217043",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names = [*filter(lambda name: len(name) != 0, female_names)]\n",
    "male_names = [*filter(lambda name: len(name) != 0, male_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d49ea4b-49aa-468f-a75e-2fe9ec4c2356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max female name len: 20 | max male name len: 18\n",
      "total female names: 17290 | total male names: 30758\n"
     ]
    }
   ],
   "source": [
    "print(f\"max female name len: {max(map(lambda name: len(name), female_names))} | max male name len: {max(map(lambda name: len(name), male_names))}\")\n",
    "print(f\"total female names: {len(female_names)} | total male names: {len(male_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c36956-7d94-4589-8077-3c58022b96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Special Tokens\n",
    "\n",
    "END_TOKEN = \"<end>\"\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "\n",
    "MALE_NAME_TOKEN = \"<M>\"\n",
    "FEMALE_NAME_TOKEN = \"<F>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750776da-4443-458d-9c3b-3a2639b71375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token2idx = {token: idx for idx, token in enumerate([chr(i) for i in range(97,123)] + [MALE_NAME_TOKEN, FEMALE_NAME_TOKEN, END_TOKEN, PAD_TOKEN])}\n",
    "idx2token = {v:k for k,v in token2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e3b8e9-bc17-4b5c-b185-374ef39bb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE      = \"cuda:0\"\n",
    "VOCAB_SIZE  = len(token2idx)\n",
    "MAX_LEN     = 24\n",
    "EMBED_DIM   = 512\n",
    "HIDDEN_DIM  = 1024\n",
    "\n",
    "EPOCHS      = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66b3406e-9b3d-45b5-89ac-2e43ce49260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenizer_encode(name, gender, max_len=24):\n",
    "\n",
    "    if gender == \"Male\":\n",
    "        gender_token = MALE_NAME_TOKEN\n",
    "    elif gender == \"Female\":\n",
    "        gender_token = FEMALE_NAME_TOKEN\n",
    "    else:\n",
    "        raise RuntimeError(\"Invalid gender\")\n",
    "    \n",
    "    name = [gender_token] + [*name[:max_len]]\n",
    "    name.append(END_TOKEN)\n",
    "    \n",
    "    while len(name) < max_len:\n",
    "        name.append(PAD_TOKEN)\n",
    "        \n",
    "    return [token2idx[c] for c in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7254b108-9c74-4fc0-85d9-20cdb9d97083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, embd_dim=EMBED_DIM, hidden_dim=HIDDEN_DIM):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.W_hh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_xh = nn.Linear(embd_dim, hidden_dim)\n",
    "        self.W_hy = nn.Linear(hidden_dim, vocab_size)\n",
    "        # self.W_hg = nn.Linear(hidden_dim)\n",
    "        \n",
    "        self.h = nn.Parameter(torch.randn(hidden_dim))\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_dim)\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, x, device=DEVICE):\n",
    "\n",
    "        # h = self.h\n",
    "        x = self.embeddings(x)\n",
    "        batch_size, seq_len, embd_dim = x.shape\n",
    "\n",
    "\n",
    "        output = torch.zeros(batch_size, seq_len - 1, self.vocab_size).to(device)\n",
    "        hiddens = torch.zeros(batch_size, self.hidden_dim).to(device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            hiddens[i] = self.h\n",
    "        \n",
    "        for i in range(seq_len - 1):\n",
    "            \n",
    "            hiddens = F.tanh(self.W_hh(hiddens) + self.W_xh(x[:,i] + x[:,0]))\n",
    "            y = self.W_hy(hiddens)\n",
    "            output[:,i] = y\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4603280f-ba95-4508-85fd-3ecf9b1e5dfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "model = RNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f2f26-68a2-4077-a7dd-9bb9284a3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def criterion(input_tokens, y_pred):\n",
    "        \n",
    "    y_true = input_tokens[:, 1:].clone()\n",
    "\n",
    "    # The first token will be the gender token\n",
    "    y_true[0] = -100\n",
    "    y_true.masked_fill_(y_true == token2idx[PAD_TOKEN], -100)\n",
    "    \n",
    "    # print(y_pred.shape, y_true.shape)\n",
    "    loss = F.cross_entropy(y_pred.reshape(-1,VOCAB_SIZE), y_true.reshape(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e3cd26e-1339-4ec9-85c9-2e2ec5523532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17290it [00:00, 406476.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 6, 20, 15, 15, 24, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30758it [00:00, 185483.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 10, 8, 17, 8, 13, 12, 0, 17, 20, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "\n",
    "for idx, name in tqdm(enumerate(female_names)):\n",
    "    xs.append(tokenizer_encode(name, \"Female\"))\n",
    "\n",
    "print(xs[-1])\n",
    "for idx, name in tqdm(enumerate(male_names)):\n",
    "    xs.append(tokenizer_encode(name, \"Male\"))\n",
    "\n",
    "print(xs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a2b4128-944b-4c1c-bae2-53dcdf3f564b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(xs)\n\u001b[0;32m----> 2\u001b[0m xs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "\n",
    "random.shuffle(xs)\n",
    "xs = torch.tensor(xs).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62053e65-b140-489f-85df-dca03f69ae96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27,  2,  0, 17, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [27,  0, 10,  0, 25, 20, 10,  8, 13, 28, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [27, 14,  2,  7,  8, 24,  0, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [26,  1,  4, 11, 11,  8, 18, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [26,  3,  0,  4, 11, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [26,  5, 20, 12,  8, 13, 14, 17,  8, 28, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [26, 18,  7,  8, 13,  0,  7, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [27, 17,  4,  1,  4,  2,  2,  0, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [26, 14, 15, 19,  8, 12, 20, 18, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [26,  2,  7,  4,  1, 20, 17,  0, 18,  7, 10,  0, 28, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29],\n",
       "        [26, 11,  4,  8, 15, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "         29, 29, 29, 29, 29, 29]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40b923e4-39b7-4ce7-aad7-5f9930a321f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 64\n",
    "optimizer = AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91c043f0-d4de-4075-a3cb-f5e69e14134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inference(model, input_str, gender):\n",
    "    \n",
    "    while True:\n",
    "        x = torch.tensor(tokenizer_encode(input_str, gender, max_len=len(input_str))).reshape(1,-1).to(DEVICE)\n",
    "        last_logits = model(x, device=DEVICE).squeeze()[-1]\n",
    "        new_char_idx = last_logits.softmax(dim=-1).argmax().item()\n",
    "    \n",
    "        if new_char_idx == token2idx[END_TOKEN]:\n",
    "            # print(input_str)\n",
    "            break\n",
    "        \n",
    "        input_str = input_str + idx2token[new_char_idx]\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aab598f-3978-4332-9512-c5fc577361ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                      | 0/751 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m input_xs \u001b[38;5;241m=\u001b[39m xs[batch_start_idx: batch_start_idx \u001b[38;5;241m+\u001b[39m BATCH_SIZE]\n\u001b[0;32m---> 11\u001b[0m pred_ys \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(input_xs,pred_ys)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(x)\n\u001b[1;32m     21\u001b[0m batch_size, seq_len, embd_dim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 24\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m hiddens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_loss = []\n",
    "step_count = 0\n",
    "inference_per_step = 50\n",
    "\n",
    "for batch_start_idx in (tbar := tqdm(range(0,len(xs),BATCH_SIZE))):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    input_xs = xs[batch_start_idx: batch_start_idx + BATCH_SIZE]\n",
    "    \n",
    "    pred_ys = model(input_xs, device=DEVICE)\n",
    "    loss = criterion(input_xs,pred_ys)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    step_count += 1\n",
    "    training_loss.append(loss.item())\n",
    "    \n",
    "    if step_count % inference_per_step == 0:\n",
    "        model.eval()\n",
    "        name = inference(model, \"y\", \"Female\")\n",
    "        print(f\"step count: {step_count} | name: {name} | gender: Female\")\n",
    "        name = inference(model, \"y\", \"Male\")\n",
    "        print(f\"step count: {step_count} | name: {name} | gender: Male\")\n",
    "        model.train()\n",
    "    \n",
    "    \n",
    "    tbar.set_description(f\"loss: {loss.item()} | training loss: {np.mean(training_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7b1fc6f-0d74-4aad-9066-eb12fdb7e964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (W_hh): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (W_xh): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (W_hy): Linear(in_features=2048, out_features=30, bias=True)\n",
       "  (embeddings): Embedding(30, 512)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "627bb61d-d23c-4746-abfd-34aeb81db92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fusana'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(model, \"fus\", \"Female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b65f6f-5c47-4fc9-bdf4-0d47c6d507a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
